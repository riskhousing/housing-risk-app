{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def stage(msg: str):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(msg)\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def timed(msg: str):\n",
    "    # simple context manager-ish helper\n",
    "    class _T:\n",
    "        def __enter__(self):\n",
    "            self.t0 = time.time()\n",
    "            print(f\"▶ {msg} ...\")\n",
    "            return self\n",
    "        def __exit__(self, exc_type, exc, tb):\n",
    "            dt = time.time() - self.t0\n",
    "            if exc_type is None:\n",
    "                print(f\"✅ Done in {dt:.2f}s\")\n",
    "            else:\n",
    "                print(f\"❌ Failed after {dt:.2f}s\")\n",
    "    return _T()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 1/7 — Load dataset + verify columns\n",
      "================================================================================\n",
      "▶ Reading data.csv ...\n",
      "✅ Done in 0.01s\n",
      "Rows: 600\n",
      "Columns: 16\n",
      "\n",
      "Target distribution:\n",
      "risk\n",
      "LOW       200\n",
      "HIGH      200\n",
      "MEDIUM    200\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAULT_DISTANCE</th>\n",
       "      <th>BASIC_WIND_SPEED</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>POTENTIAL_LIQUEFACTION</th>\n",
       "      <th>DISTANCE_TO_RIVERS_AND_SEAS</th>\n",
       "      <th>SURFACE_RUN_OFF</th>\n",
       "      <th>VERTICAL_IRREGUARITY</th>\n",
       "      <th>BUILDING_PROXIMITY</th>\n",
       "      <th>NUMBER_OF_BAYS</th>\n",
       "      <th>COLUMN_SPACING</th>\n",
       "      <th>MAXIMUM_CRACK</th>\n",
       "      <th>ROOF_SLOPE</th>\n",
       "      <th>ROOF_DESIGN</th>\n",
       "      <th>ROOF_FASTENER_DISTANCE</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.50</td>\n",
       "      <td>147.16</td>\n",
       "      <td>5.74</td>\n",
       "      <td>116.33</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>17.31</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NO</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>5</td>\n",
       "      <td>5.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>30.91</td>\n",
       "      <td>GABLE</td>\n",
       "      <td>9.30</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.62</td>\n",
       "      <td>181.23</td>\n",
       "      <td>2.42</td>\n",
       "      <td>45.84</td>\n",
       "      <td>LOW</td>\n",
       "      <td>2.03</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NO</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>5</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>34.37</td>\n",
       "      <td>HIP</td>\n",
       "      <td>14.67</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.97</td>\n",
       "      <td>225.99</td>\n",
       "      <td>26.19</td>\n",
       "      <td>12.54</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.29</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>YES</td>\n",
       "      <td>CLOSE</td>\n",
       "      <td>3</td>\n",
       "      <td>8.29</td>\n",
       "      <td>3.54</td>\n",
       "      <td>6.78</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>27.66</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAULT_DISTANCE  BASIC_WIND_SPEED  SLOPE  ELEVATION POTENTIAL_LIQUEFACTION  \\\n",
       "0           46.50            147.16   5.74     116.33                 MEDIUM   \n",
       "1           12.62            181.23   2.42      45.84                    LOW   \n",
       "2            0.97            225.99  26.19      12.54                   HIGH   \n",
       "\n",
       "   DISTANCE_TO_RIVERS_AND_SEAS SURFACE_RUN_OFF VERTICAL_IRREGUARITY  \\\n",
       "0                        17.31            GOOD                   NO   \n",
       "1                         2.03            GOOD                   NO   \n",
       "2                         0.29        MODERATE                  YES   \n",
       "\n",
       "  BUILDING_PROXIMITY  NUMBER_OF_BAYS  COLUMN_SPACING  MAXIMUM_CRACK  \\\n",
       "0           MODERATE               5            5.83           0.07   \n",
       "1           MODERATE               5            5.16           0.17   \n",
       "2              CLOSE               3            8.29           3.54   \n",
       "\n",
       "   ROOF_SLOPE ROOF_DESIGN  ROOF_FASTENER_DISTANCE  risk  \n",
       "0       30.91       GABLE                    9.30   LOW  \n",
       "1       34.37         HIP                   14.67   LOW  \n",
       "2        6.78        FLAT                   27.66  HIGH  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage(\"Stage 1/7 — Load dataset + verify columns\")\n",
    "\n",
    "DATA_PATH = \"data.csv\"\n",
    "TARGET_COL = \"risk\"\n",
    "\n",
    "FEATURES = [\n",
    "    \"FAULT_DISTANCE\",\n",
    "    \"BASIC_WIND_SPEED\",\n",
    "    \"SLOPE\",\n",
    "    \"ELEVATION\",\n",
    "    \"POTENTIAL_LIQUEFACTION\",\n",
    "    \"DISTANCE_TO_RIVERS_AND_SEAS\",\n",
    "    \"SURFACE_RUN_OFF\",\n",
    "    \"VERTICAL_IRREGUARITY\",\n",
    "    \"BUILDING_PROXIMITY\",\n",
    "    \"NUMBER_OF_BAYS\",\n",
    "    \"COLUMN_SPACING\",\n",
    "    \"MAXIMUM_CRACK\",\n",
    "    \"ROOF_SLOPE\",\n",
    "    \"ROOF_DESIGN\",\n",
    "    \"ROOF_FASTENER_DISTANCE\",\n",
    "]\n",
    "\n",
    "with timed(f\"Reading {DATA_PATH}\"):\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "\n",
    "missing = [c for c in FEATURES + [TARGET_COL] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "df = df[FEATURES + [TARGET_COL]].copy()\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[TARGET_COL].value_counts(dropna=False))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 2/7 — Define feature types\n",
      "================================================================================\n",
      "Categorical features: ['POTENTIAL_LIQUEFACTION', 'SURFACE_RUN_OFF', 'ROOF_DESIGN', 'VERTICAL_IRREGUARITY', 'BUILDING_PROXIMITY']\n",
      "Numeric features: ['FAULT_DISTANCE', 'BASIC_WIND_SPEED', 'SLOPE', 'ELEVATION', 'DISTANCE_TO_RIVERS_AND_SEAS', 'NUMBER_OF_BAYS', 'COLUMN_SPACING', 'MAXIMUM_CRACK', 'ROOF_SLOPE', 'ROOF_FASTENER_DISTANCE']\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 2/7 — Define feature types\")\n",
    "\n",
    "categorical_features = [\n",
    "    \"POTENTIAL_LIQUEFACTION\",\n",
    "    \"SURFACE_RUN_OFF\",\n",
    "    \"ROOF_DESIGN\",\n",
    "    \"VERTICAL_IRREGUARITY\",\n",
    "    \"BUILDING_PROXIMITY\",\n",
    "]\n",
    "\n",
    "numeric_features = [c for c in FEATURES if c not in categorical_features]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 3/7 — Build preprocessing pipeline\n",
      "================================================================================\n",
      "✅ Preprocess pipeline created.\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 3/7 — Build preprocessing pipeline\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✅ Preprocess pipeline created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 4/7 — Train/validation split\n",
      "================================================================================\n",
      "▶ Splitting train/val ...\n",
      "✅ Done in 0.01s\n",
      "Train size: 480\n",
      "Val size: 120\n",
      "\n",
      "Train target distribution:\n",
      "risk\n",
      "MEDIUM    160\n",
      "HIGH      160\n",
      "LOW       160\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val target distribution:\n",
      "risk\n",
      "HIGH      40\n",
      "LOW       40\n",
      "MEDIUM    40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 4/7 — Train/validation split\")\n",
    "\n",
    "with timed(\"Splitting train/val\"):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y if y.nunique() > 1 else None\n",
    "    )\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Val size:\", len(X_val))\n",
    "print(\"\\nTrain target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nVal target distribution:\")\n",
    "print(y_val.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 5/7 — Train RandomForest (with progress)\n",
      "================================================================================\n",
      "▶ Fitting model (watch verbose output below) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done in 0.24s\n",
      "✅ Training finished.\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 5/7 — Train RandomForest (with progress)\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=150,        # prototype speed; increase later if needed\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,               # IMPORTANT: use all cores\n",
    "    verbose=1                # shows training progress in output\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "with timed(\"Fitting model (watch verbose output below)\"):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 6/7 — Evaluate\n",
      "================================================================================\n",
      "▶ Predicting on validation set ...\n",
      "✅ Done in 0.04s\n",
      "Confusion matrix:\n",
      "[[40  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  0 40]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HIGH       1.00      1.00      1.00        40\n",
      "         LOW       1.00      1.00      1.00        40\n",
      "      MEDIUM       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 6/7 — Evaluate\")\n",
    "\n",
    "with timed(\"Predicting on validation set\"):\n",
    "    pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_val, pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Stage 7/7 — Save model for FastAPI\n",
      "================================================================================\n",
      "▶ Saving model to model.joblib ...\n",
      "✅ Done in 0.06s\n",
      "✅ Saved: model.joblib\n"
     ]
    }
   ],
   "source": [
    "stage(\"Stage 7/7 — Save model for FastAPI\")\n",
    "\n",
    "MODEL_OUT = \"model.joblib\"\n",
    "\n",
    "with timed(f\"Saving model to {MODEL_OUT}\"):\n",
    "    joblib.dump(clf, MODEL_OUT)\n",
    "\n",
    "print(f\"✅ Saved: {MODEL_OUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
